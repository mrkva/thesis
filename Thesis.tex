\documentclass[12pt,a4paper,oneside]{report} 
\usepackage[utf8]{inputenc} 
\usepackage{apacite} 
\usepackage{cmap} 
\usepackage{url}
\usepackage[T1]{fontenc} 
\usepackage[osf]{libertine} 
\usepackage[scaled=0.80]{beramono}
%\PassOptionsToPackage{scaled=0.75}{beramono}
\usepackage[parfill]{parskip} 
%\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}



\title{Artistic approaches in sonification\\ and other works} 
\author{Jonáš Gruska\\
Bachelor's Thesis\\
Institute of Sonology} 
\date{\today}

\begin{document}

\frenchspacing
\raggedbottom
\doublehyphendemerits=10000       % No consecutive line hyphens.
\brokenpenalty=10000              % No broken words across columns/pages.
\widowpenalty=9999                % Almost no widows at bottom of page.
\clubpenalty=9999                 % Almost no orphans at top of page.
\interfootnotelinepenalty=9999

\maketitle

\begin{abstract}
\end{abstract}
\clearpage
\setcounter{page}{3}


\chapter*{Acknowledgements}

\tableofcontents

\chapter{Introduction}


\chapter{Sonification and audification experiments}

\section{Thoughts on current state of sonification}

% What is this chapter gonna be about

Topic of sonification is intriguing for few reasons. First of them could be, that it benefits from interest from various groups of people, scientists - from biologists, through mathematicians, creatives - from musicians and sound artists and general public. Another is a belief, that this topic still has a lot of unrevealed potential. I will try to discuss this clash between scientific and artistic approach, various significant projects or artworks, as well as fields of opportunity blossoming from this duality.


% Sonification definition
Main understanding of the term \emph{sonification} is the \emph{``use of non-speech audio to convey information''}, or more precisely, it is the \emph{``transformation of data relations into perceived relations in an acoustic signal for the purposes of facilitating communication or interpretation''} \cite{Fitch}. These are definitions from probably the most relevant place to sonificication - International Community for Auditory Display, which organizes conferences and publishes books on the topic since 1992.

%That is a definition made by ICAD (International Community for Auditory Display), which is one of the main research organizations in the field organizing annual International Conference for Auditory Display.
Nicolas Collins puts it less formally, as a method for one to provide \emph{``aural alternatives to pie charts, line graphs and spreadsheets''} \cite{Collins2006}. All these quotations define it as an analytical, representative point of view, and the reasoning behind the use of sonification in this sense is repositioning of the information from traditional semantic, visual or statistic level to sonic level giving ground to non-traditional data analysis via medium of sound or music. Interestingly, ICAD's first definition mentioning conveying \emph{information} rather than data can also give an understanding that sonification is not only about data patterns; and whether we try to sonify weather forecast, biological systems or our emotions is secondary.

% Division proposal
I would like to propose a division in this definition. There is one part of sonification world, described above - that is an analytical, `auditory display' stand. My proposition adds \emph{an artistic stand}, where the main goal of the process is not to make certain data accessible for aural analysis, but rather to use those data as a essence of specific aesthetics. That means, one is no more looking for an scientific tool, but on a sonic instrument, source of inspiration and compositional data. It might as well be described as a matter of aim behind the use of sonification methods in his work: whether works are aimed to inform a listener or provide him and auditory display of some data, or sonification is used for its characteristic aesthetics.

Some scientists residing on the analytical side are concerned with addition of music grammar and finesse, because it might get in the way of the data representation, \emph{``the music would be another language to learn''} \cite{Vickers2006}.

Use of streams of data for compositional and sound generating purposes is very familiar to electro-acoustic composers, artists and performers. Sonification in artistic stand is pushing the idea a little further - instead of algorithms, `real world' data are used, although reaching their exact, understandable representation becomes additional or even insignificant rather than essential.

%Benefits of sonification\\
%- pattern substraction\\
%- abilitity to filter in frequency domain\\
%- ability to focus on details in various distances\\
%\\
%\cite{Hermann2011} page 3

%Reduced listening vs. Causal listening\\
%\cite{Vickers2006} page 2

%SNIPPETS:\\*

Next, I would like to point out few significant works which use sonification as its main concept or method, and while doing so, I will try to exercise my proposal for the new sonification definition division.

One of the most classic examples of sonification is \emph{Geiger} (or \emph{Geiger–Müller}) \emph{counter}, particle detector measuring ionizing radiation. Method of display of the information is use of pulses - representations of electrical charges (and consequential dicharges) of the inert gas in the Geiger–Müller tube caused by particles or photons of radiation. Higher amount of electrical discharges (being higher amount of audio pulses coming from speakers) is signaling greater density of particles of radiation, thus higher radiation in the environment. \cite{Knoll2010} Geiger counter is clearly a \emph{analytic} sonification tool, with its main purpose being representation of certain information, rather than using the information as an artistic basis.

I have chosen Geiger counter for another reason than simply being ideal representation of scientific and analytic attitude towards sonification. It is also a standalone and portable instrument. This opens up a possibility for its artistic use, even though its design is purely for research purposes. As I suggest later on in subsection discussing my wireless sonification project, I find interest in portable sonification tools for various environmental experiments.

Geiger counter can be also viewed as representation of sub-method of sonification, \emph{audification}. \emph{``Audification is a technique of making sense of data by interpreting any kind of one-dimensional signal (or of a two-dimensional signal-like data set) as amplitude over time and playing it back on a loudspeaker for the purpose of listening.''}(Chapter 12, Sonification Handbook) 

Audification is sonification simplified to most basic level. Most of the common real-time sonifications are than audifications as well, e.g.\ listening to the whale songs or bat echolocation.

One of the most interesting sonification works is work of Christina Kubisch\footnote{I have chosen Christina Kubisch as a icon of a method, but there is a wider spectrum of artists using the same tools.}. Kubisch is focusing on audification of electromagnetic fields with the use of induction coils, headphone amplifiers and headphones. This works as a nice example of artistic audification, where the purpose seems to be in finding of interesting sounds within the world of electromagnetic fields rather than scientific analysis. 

Induction coils are acting as antennas and natural amplifiers, filters which when in right setting, can provide excellent tools for electromagnetic sensing. AC oscillations of the electromagnetic field are inducted on the coil, thusly creating AC current. This AC current is than amplified and can be directly used with any audio devices.

I have designed a simple pocket amplifier for this purposes called \textbf{Eletrosluch} (see ~\ref{fig:elektrosluch}). This device provides 100x gain for the coils and is powerful enough to drive headphones. Its main benefit is the size and portability, ideal for electromagnetic sonic explorations. The version 1.0 (on the picture) used tape head which I have extracted from old tape player as induction coil. Amplifying circuit was based around LM386 amplifier, which I have replaced in v1.1 with low-noise operational amplifier TL071. Tape heads have been replaced with ``pick-up coils'', which were, while attached with its suction cup to telephone headset, used for noise-less recordings of telephone calls in previous century. 

\begin{figure}  
  \centering
    \includegraphics[width=0.7\textwidth]{img/elektrosluch}
	\caption{Elektrosluch 1.0}
	\label{fig:elektrosluch}
\end{figure}

Probably closest to my sonificiation work is the one by Michael Chinen\footnote{\url{http://michaelchinen.com}/} and Shintaro Miyazaki's Institute for Algorhytmics\footnote{\url{http://www.algorhythmics.com/en/}}. 

Michael Chinen is an Dartmouth College graduate, sound artist and one of the developers of popular open source audio editing software Audacity. His artistic focus resides in software sonification, in sense of method as in sense of target. Prove to this claim are his works \textbf{lstn} and \textbf{FuckingWebBrowser}, which I will now try to examine in greater detail. 

Both \emph{lstn} and \emph{FuckingWebBrowser} are based around sonification of computer based streams and data. To be more precise, lstn is \emph{``a program that sonifies real-time debugging data of other programs''} and FuckingWebBrowser is \emph{``simple mac web browser with memory sonification based on WebKit''} \cite{Chinen2010, Chinen2010a}.

These works are quite similar to my work Sonodump\footnote{More information about Sonodump can be found in 2.2 Wireless sonification}. For example, as well as Chinen in FuckingWebBrowser, I also deal with browsing of the internet as with the initial trigger and data stream for sound generation. One might find it as analogous action to e\.g.\, bowing of a violin. Address bar becomes a bow and stream of data (conscious decisions about URLs to type in the address bar) is the angle and pressure of the bow on the strings. 

Chinen makes an excellent point for artistic stand towards sonification. Aim towards translating real information towards listener is missing (maybe only to a very experienced one); use of sonification plays a different, artistic, role, rather than the one of auditory display. This role being pure source of data for sound generation, not a source of information meant to be mediated towards audience.

His work is representative and direct, yet its main point its not to convey information. Auditory display becomes `useless' from scientific or research point of view and becomes interesting as an artwork for its specific aesthetics.

Chinen's work has been strongly connected to Institute for Algorhytmics, led by Shintaro Miyazaki\footnote{\url{http://www.algorhythmics.com/persons/miyazaki/}}. He is a post-doctoral researcher at Humboldt University in Berlin dealing with \emph{``epistemology, archeology, history and theory of everyday technologies, which store, transmit and process informations and their dynamic relation to sound, rhythms and other sorts of time-varying signals.''} \cite{Miyazaki2012}. From his projects, I want to point out his collaboration with Martin Howse\footnote{\url{http://www.1010.co.uk/}} called \textbf{Detektors}\footnote{\url{http://detektors.org}}.

Detektors is \emph{``an open, collaborative project which uses sonic strategies and DIY-devices to make audible the hidden infoscapes of our time. The present website will show data, recordings and cartographies of different spectral ecologies and trans-sonic machinic agencements.''} \cite{detektors}. Website of the project contains many sound recordings of the electromagnetic fields (audifications) from radio-frequency range as well as cartographic information about such sources. It is a study of electromagnetic pollution, sonic behavior of digital devices in the context of geolocational sound recordings.

\begin{figure}  
  \centering
    \includegraphics[width=0.7\textwidth]{img/detektor}
	\caption{Detektors "Detektor" device}
	\label{fig:detektor}
\end{figure}

For ``detection'', specially designed device is used as seen on figure ~\ref{fig:detektor}. Core of the hardware is handy logarithmic detector chip AD8313 produced by Analog Devices. This chip takes AC signals from up to 2.5 GHz  (upper border most used wireless network range is 2.4 Ghz \cite{802}) and demodulates it into audible sphere. This is somehow similar to work of Kubisch, but there is a difference in the frequency spectrum target. Method using induction coils provides us only with electromagnetic AC signal within our hearing range and within the limitations of the amplifying system, but method using demodulator allows us to listen to e.g.\ bluetooth and wireless radio communication. Interestingly, Detektors and Kubisch's work both share emphasis on placing of their sonic discoveries within cartographic space.

%Sonification of objects using distance sensors.
Another case to study and analyze might be a project of Gil Weinberg called \emph{BrainWaves}. It is based on interactive auditory research of electrical stimuli applied to \emph{in vitro} neuron cultures. I picked the project for the collision of scientific and artistic approach in the work.

To briefly describe the project, \emph{BrainWaves} is \emph{``sonification installation that allows a group of players to interact with an auditory display of neural activity. The system is designed to represent electrical spike propagation in a neuron culture through sound propagation in space. Participants can simulate neural spikes by using a set of specially designed controllers, experimenting and sonically investigating the electrical activity of the brain.''} \cite{Weinberg2006}

The particular part which caught my interest is desire to experiment with the subject of sonification interactively. Classic idea of stream of data is missing - instead of discrete information there is a system, which needs to be sonified. As a comparison, one can imagine hitting an oil barrel in a goal of exploring its acoustic properties - physical model or a `system' of the subject.

Since main subject of the auditory display is propagation pattern simulation, the authors have decided to use spatialization as key element of representation. As they argue against visual display, \emph{``sonification can be more effective than visualization in such a spatial application because the human auditory system is able to perceive synchronous spatial stimuli from every point within a space, while visual perception is limited to physical range of sight.''} For the purpose, 8 speakers in space are used to provide sufficient clues for the exact propagation pattern.

For the interactive standpoint, custom made drum trigger instruments were created using piezo elements to represent electrical spikes in the system. Performers are asked to hit these in specific way - after first propagation ends, performer placed closest to its ending is bound to start another one, by hitting his own instrument. At this point one could see an interesting connection between \emph{sonification} and \emph{gamification} as very close methods of bringing data streams and system under closer, possibly more understandable examination.

As authors conclude, the method of using almost only spatialization for auditory display purposes was not completely successful, since they noticed that part of performers was using visual representation of the process (provided during event) to orient in the process rather than simply listen to the positioning. 

From the analysis stand point, I see this work as bordering between scientific and artistic approach. The effort to analyze real scientific system combined with use of almost musical methods and instruments seems as interesting way of reaching sonologicaly relevant results. It seems that authors have not seen scientific results as the pure purpose of the work - using (musical) instruments, focus on aesthetics of the 

- spatialization - dimensional propagation of the neural spikes in neural cultures

\section{Wireless network sonification}

As a part of my experimentation with untraditional sources for musical or generally sonic data I decided to extend my line of work on the layer of wireless networks. Project I would like to describe in this chapter is dealing with wireless network sonification as a main artistic source for sonic performance and installation. In basic terms, it catches data streams `from the air' and transforms them directly into sound using set of tools and methods. This work has been presented as a performance and an installation. In case of performance, I have used \emph{live coding} technique to change the aspects of the sonification and I performed by interacting with the data stream itself, generating artificial traffic on the network.

\subsection{Work process and technical details}

To get into more detail, first I would like to define some basic terms of the technical side of the project and then continue by describing my point of view on even more important social and artistic side.

% Describe the whole concept in general first
% As musician using a metal box for performance
% Ffffucking web browser
One of the core subjects related to this field are \emph{packet analyzers} or \emph{sniffers} – tools for silent interception of network traffic. In technical terms, it is software (or hardware) which passively receives all data link layer frames passing through the device’s network adapter, not just those directed towards recipient. They are generally used by hackers, while also having legitimate use by system and network administrators or security experts. Sniffing is possible due to the physical characteristic of network. Either with LAN (Local Area Network) or unencrypted WLAN (Wireless LAN), all data passing through the system are accessible to everyone. It is than a job of WLAN or LAN adapters (network cards) on the site of client to separate its part of the data using filtering based on MAC (Media Access Control) address. MAC address is an unique identifier of every network adapter. Except simple network MAC filtering, it can be for example also used for assigning IP address by DHCP (Dynamic Host Configuration Protocol).

By enabling functionality of network device called \emph{promiscuous mode} one is able to avoid this filtering and obtain all present network data. This is possible as well as for wired as for wireless adapters, thus for wired or wireless networks. Of course there are certain limits to this, for example when a \emph{network switch} is placed in the network, it is not possible to receive everything. Network switch, different from \emph{repeater} or \emph{hub} (device only physically `multiplying' the cable), is more advanced device and acts as a MAC filter by itself. \cite{Pallavi2012}

A classic example of a sniffer is \textbf{tcpdump}. Tcpdump was developed at University of California in 1987 by Van Jacobson, Craig Leres and Steven McCanne and its main use is traffic analysis. Unix Manual entry describes it as ``dump traffic on a network'', but that is very reducing. Over the years since its first release it has become a rather complex and powerful tool. One of the features of tcpdump is that it can work easily with both LAN or WLAN packets and therefore provides us with various data sources for our artistic purposes. Because of its enormous functions on one hand and lightweight operation on other, it has become my favorite tool for wireless network sonification and will be discussed more later on in the text.

In the beginning of my research I was considering few options, ways, and processes. I was motivated to learn C programming related to audio, so that became my first choice. It has started by writing my own sniffer, based on library developed by same tcpdump developers. Library is called \textbf{libpcap} (PCAP stands for Packet CAPture) and serves for implementation of tcpdump functionality to one's software. Obviously, this wasn't very easy task to do, especially for unexperienced C programmer as myself. After I finally managed to sniff data using my software, the next step was to use \textbf{PortAudio} library to implement the audio part of the project.

Finally I partly succeeded, by writing \emph{Sonodump}. Sonodump worked exactly as I wanted - it `sniffed' the network data and reflected current traffic. The conversion was done through treating data harvested from the network as audio data - simple WAV file. User has only two options to select from - which interface should be used (wireless or wired) and what sample rate is expected. Use of the term sample rate is a bit inaccurate, because there is no correct, real sample rate of the stream - it is not audio stream. We can just guess or purposefully select some value to affect the way sonification behaves. Lower sample rates result in rather low-frequency based sonic content and higher contain more higher frequencies. This occurs simply because of the speed the network data are read, as it can be described as an obscure case of wavetable synthesis with tables generated in the network stream.

Sonodump already gave some interesting results, yet it wasn't very efficient. My programming skills weren't just on the right level to optimize the code properly. Therefore I need to look for other options. In autumn 2011 I was asked by organizer of AudioArt festival in Krakow, Marek Chołoniewski to present my sonification work on his festival. I happily agreed and immediately thought of wireless sonification project. But Sonodump wasn't enough in this case - I needed something more adjustable, powerful and interesting.

One of the questions was whether to treat the sonification process in more traditional way, lacking interaction with the stream which is being sonified. I felt inner conflict between keeping certain level of purity and working on the most successful and pleasant aesthetic experience. In the end the idea of live interaction with the stream of data won, with argument planning for achieving non-traditional way of control over the resulting sound. With image of this wild, partly unpredictable instrument I started to research other technical solutions.

As mentioned before, Sonodump was not optimal and had few bugs, and in a meanwhile I discovered very useful set of commands present on Linux systems. Main motivation for work with Linux / UNIX was system shell - terminal, allowing scripting and importantly for this project, \emph{pipelining} and \emph{redirecting}, providing user with methods for interconnecting processes and files. For example, output of one process can be streamed in real time to another without user caring about any `middle-man' text file or thinking about memory allocation. This comes particularly handy when you want to \emph{sonify} something. 

Good example is redirecting of an non-audio file to sound card. What this represents is treating the file as a stream of data consequently output to the sound card as it would be audio data - coming for example from a mp3 player. On some distributions it is enough to write this command to the terminal:
\begin{quotation}
	\texttt{cat SONIFY\_ME.txt > /dev/dsp} 
\end{quotation}

Command \texttt{cat} read the file \texttt{SONIFY\_ME.txt} - which is an regular text file and using the symbol \texttt{>}, bash takes care of writing it to \texttt{/dev/dsp} - which is a virtual port for sound card. Writing to this port opens a stream on the sound card and plays given data as audio. I have ran into few people exercising this process, usually more Linux enthusiasts than musicians. 

Basic process of reading network data and converting them directly to sound is not much harder. The \texttt{cat} command is now replace with \texttt(tcpdump), which is a tool mentioned before - traffic analyzer, \emph{sniffer}.
\begin{quotation}
	\texttt{tcpdump -i wlan0 -A > /dev/dsp} 
\end{quotation}

Tcpdump opens a packet capture at device \texttt{wlan0} (wireless module). Option \texttt{-A} represents conversion of the characters to ASCII symbols (so we can always read them in terminal). This already gives us some amount of sonification of the network with just single line of code. 

Next step was to think about what other ways are there to experiment with. One of the options was change of the sample rate of the /dev/dsp (sound card) on-the-fly and thus change the resulting sound as with Sonodump. After some research on the topic it seemed rather complicated and bulky to do, so I had to think of some other method. That was when I discovered \textbf{aplay}, part of ALSA. ALSA is amongst OSS and Jack one of sound systems used for audio on Linux. The two most important functions of aplay for me were the possibility to read data from pipeline and to modify couple of the parameters of the reading. Great addition was that there is a way to have almost unlimited amount of aplays playing at the same time, even from one source, ALSA is handling the mixing of the streams to DAC.

From the artistic standpoint...

\section{City attributes sonification}

%\chapter{Modularity and physical instruments}
%\section{Reinvention of the physical musical environment}
%\section{Musical use of microcontrollers and low-level computers}
\chapter{Other works} 
\section{Binmatu} Binmatu is an audiovisual drone performance I have been executing during last two years.

\subsection{Introduction} I have never been very extensive listener of drone music and I could hardly relate to most of the works I have heard. The idea of extremely slow movements didn't please me aesthetically nor technically. At the time, I preferred wild improvisations with high pace of changes and especially high variety of sonic content.

This has changed when I have ran into works by Phill Niblock and La Monte Young. I realized, that drone music needs its own time to be perceived properly. One could say it needs to induce some kind of a trance state, where person becomes hypnotized by the simplicity of the composition and sound. At that point, the subtle changes start to make sense and whole world of microscopic compositions and performances starts to occur. Our ears (and brain) finally start to focus on details, which as under magnifying glass, have liberty to become big movement, filled with spine-chilling realizations.

In particular, I was heavily impressed by Phill Niblock's work, 22 minute long \emph{A Trombone Piece}, for trombone and tape machine, which works as a looper. There are possibly just 2 or 3 notes played (within interval of a second) during the whole work, yet it creates astoundingly heavy and dense atmosphere. Nothing really happens, just short breaks of the player for inhaling before upcoming blow. Sonologists may hear comb filtering occurring on overlaying trombone signals and frequency beating. Our perception, missing the regular level of stimulation starts to work differently and becomes more sensitive to slight details. My listening changes over the whole duration of the piece, from the regular alert position of a listener to meditative and contemplated state of mind. 

\subsection{Starting point} My work started at the point of musical hibernation in some sense. I was at that moment doing artistic residency at OKNO medialab in Brussels, dealing with my project of designing open source modular gardening system. Most of the day surrounded by soldering iron, electronic components and working on the code. I wasn't communicating with many people during the day and my only companion was a computer (and social contacts accessible through it). It was a strange mental state, where I experienced many hours of silence and loneliness. I feel it is important to describe these conditions, because I believe they are very much reflected in the resulting work. 

I started composing one night. For me as sonologist, composing often means writing code. To elaborate, after four years at Institute of Sonology, I sometimes see myself as composer which have exchange five line staff with (five) lines of code - writing algorithms is writing music. And that is what I was doing, writing line after line. It started very simply as few sine waves in specific relationships, slowly coming and going into the space. Bending their frequencies with almost momentary inaudible results, yet creating something special over the long run. I was immediately charmed by the two facts - simplicity of the composition and the efficiency of such work. I started noticing subtle changes in my state of mind - it was so delicate at first, but after letting my piece playing for longer time (10-20 minutes) I was falling into trance state where the sound would escape boundaries of its physical body. This experience was very frightening but also very rewarding. I suddenly felt very powerful, sort of holding sound in my hands. 

\subsection{Binmatu} After some time, I have ended up in 4 core works. They all use sets of basic oscillators which are modulated with other set of slower oscillators. All frequencies are picked empirically, ``by ear'', based on their sonic impact. I already knew the theory of binaural beats and similar psychoacoustic effects, yet I decided not to use it consciously, but more in empiric fashion of being the testing and tested subject.

In the first performances of this project, I have experimented with adding a my (heavily processed) vocal to the works, but it turned out as a dead end. My views on the whole concept of this particular performance has changed and crystalized into cleaner, minimalistic level. Vocal was redundant at this part, as I decided for a cold, digital and unstoppable feeling. Singing seemed too weak and pointless against the mass of heavy frequencies. 

At this point, I started to experiment with the strategy of infinite pieces. Something which can be easily faded in and out at any point of its being and reach the same desired experience. Ongoing self-controlling drone, complex enough in its innards to maintain certain degree of non-repetitiveness (if possible in such genre). This idea is presented in my other works related to Binmatu mentioned later. 

I started to orient more on visual accompaniment to the sound works, since I have small experience in that field. During my listening sessions, I have over few days programmed 4 visual compositions for each piece. The visuals were purposefully not directly connected to music, but strongly connected in conceptual sense. They represent very subtle changes and one needs to experience them for longer period of time to appreciate their potential. This effect is partly achieved by creating ``moiré'' from huge quantities of rather primitive shapes. Visual itself is than, in contrast to simplicity of its essential building blocks, quite complex. This particular effect might be found analogous to wave interactions, e. g.\ beating created by interaction of two sine waves with close frequencies. As plain lines, when placed closely enough and reduced in digital domain to pixels, create pulsating waves and circles due to aliasing, interacting frequencies create characteristic pulsation of third frequency born of collision of two waves. As in the musical part, changes are very slow. Some transitions even take through the whole piece to be noticeable.

From technical point of view, I am mainly using trigonometric functions for their rhythm and organic quality. These are fed with variables which are growing over the period of the whole piece, thus resulting in certain form of repetitive behavior when fed to e. g.\ sine function and linear narrative when used as direct controls of the attributes. Use of color is rather minimalistic, there is rarely more than 2 or 3 colors present.

After set of performances in Belgium, Czech Republic, Poland and Slovakia I was asked to create a new set for performing at NEXT festival in Slovakia. I have composed 9 new works and 9 new visuals in similar manner as the previous ones. There appeared a slight shift towards other psychoacoustic effects, from binaural beats (as in first works) towards Haas effect and other space illusions.

One particular composition is based around time delayed pulses, where the length of the delay is gradually shifted over the time by small steps. I have achieved this with setting up two separate pulses (one in each channel), with slight difference in frequency. I have calculated the difference in a way, that the pulses come to the temporary synchronization every 4 minutes (which is constant length of my works in this project). Use of pulses brings another spatial effect, and that being impulse response of the space. Frequency of the pulses gives sufficient time (142 milliseconds) for revealing the natural resonances and reverberations of the space. One can also perceive compression algorithm of the ear, which brings (in audio engineering slang, ``pumps'') these effects up between each pulse.

\subsection{Selected performances and installations} In this section, I would like to describe and evaluate some of Binmatu performances and installations. From performances, I have selected two most recent ones, quite different from each other providing ground for comparisons. First being performance in Studio Loos in The Hague during one of the \emph{Ephémère} evenings organized by Marie Guilleray. 

This event consisted from quite different performance, from experimental amateur vocal performances of graphical scores (Genetic choir \& Tanja Smit) to pop songs of Kathrin Grenzdörffer and her project \emph{Glanzkoffer}. Binmatu was scheduled last, which was from my experience a good decision. Unfortunately, by the time of the performance, big part of the audience left due to late hour. Since Loos offers quad-speaker setup, I decided to use it for my work by mapping front channels to rear in reverse. During my soundcheck I have prepared the speaker in traditional symmetric fashion, but over the night I noticed that listeners have chosen rather untraditional positions in the space, so I improvised and modified the directions of the rear speakers to cover sides of the small room rather than the center (which was already covered by front speakers). I was expecting a lot of interactions, comb filtering, reverb and other acousticians nightmares. Not being acoustician, I personally enjoy these effects very much and they have became an inspiration for further works and installations. 

As expected, sound was behaving oddly and quickly conquered the whole room. Judging from the point of a performer (partly out of the system), transients were completely lost in the reflections and reverb. Presence of the low frequencies was slightly lower, but as I said, I was happy with all the imperfections and acoustic errors of the space, because they served my purposes well.

Second event mentioned, contrasting to small studio performance, is \emph{Sonology Discussion Concert} presented in Arnold Schoenbergzaal of Royal Conservatory in The Hague. Arnold Schoenbergzall is spacious concert hall designed for larger events of various genres of music. For my years at Sonology, it has been a home to most of Sonology concerts. It was a special moment for me to finally present my work in such place and I treated it with adequate dignity.

I have once again benefited from quad-speaker setup, and this time the order of rear speakers wasn't reversed. It has been quite successful in its realization. There were some minor disturbances with distortion of the speakers / mixing console at few points, but in the end I was satisfied with results. Hall provided sufficient ground for the grandiosity of certain pieces and previously described ``impulse'' piece had enormous impact because of the natural reverberation, which haven't smothered transients, yet allowed blossoming of impulse responses.

\subsection{Conclusion} Binmatu is still ongoing project. Over the course of year and a half, it has developed from uncertain coasts of self-searching vocal performance to clean and direct \emph{digitalism}. I still see myself with lack of expertise in performative aspect of the performance. I feel I need to research more art works dealing with ``musical spirituality'', ways of reaching deep into human mind, further than simple emotions, through medium of sound. After one of the performances, one composer studying classical composition in Bratislava, Slovakia came to me and said that he had very strange experience. He told me, that he has ``been places and remembered things which he believed were long forgotten''. I view it as beautiful compliment, especially, because at that point I knew I am not alone who perceives the psyche-delic (I choose to divide this word to embrace its original meaning) energy stored within these simple sounds. Other compliment I want to point out was from a girl, which pronounced, that she wasn't able to focus on any music after my performance. It worked as some kind of special spell which simply didn't let her to concentrate and listen during the rest of festival. I found it quite beautiful, I was astonished that my pieces can reach such levels of impact. How far can I possibly reach?

For the future, I see myself starting to work with Binmatu installations as well. Effort to transform my performance into infinite streams of sound and visuals. Embracing the site-specificity - use of the acoustic properties of spaces, illusions, use of present objects as speakers with use of tactile transducers.

\section{Phasolume} Phasolume is an audiovisual installation that I've authored in collaboration with Agnes Szelag.

\subsection{Introduction} In 2011 and 2012 I have done a student exchange at Academy of Music in Cracow. This visit has resulted in few different collaborations, and I especially started to collaborate with Agnes Szelag, which has been on a residency at same place. Agnes Szelag is a California based sound artist, performer and composer. After receiving her title from Mills College, she performed and presented her work on festivals around USA and Europe. She has also authored few audiovisual installations. 

At the beginning of the year, Szelag started a group called Krakow Active Ensamble, which connected various musicians from the conservatory into one unifying experience of free improvisation and graphical scores. For my part, I have been mostly using my own software programmed in Max, JONO. Ensemble have been performing on various occasions in galleries, electroacoustic events and open jam sessions.

In the beginning of 2012, Agnes and I have decided to prepare an installation together. We both have made some works in this field before, but our standpoints were rather different. My main skill is dealing with technical concepts and hers was more of a conceptual and esthetical level - outlook on the work as a whole unit. 

\subsection{Working process} Our basic idea was to implement organic behavior, imitation of processes observed in nature using sound and light. We believe, that such methods, when used correctly, can relate to some specific parts of our aesthetic appreciation. At the beginning, we wanted to place our installation permanently in some abandoned building. After some research and brainstorming, we have changed the plan to create and present installation directly in my apartment. Since I had one extra room which could have been used exactly for this purpose, it became an ideal environment. It is not very often that one has opportunity to work on installation not limited by time or gallery factors.

By the end of March, we have slowly started to grasp an idea for specifics of the project. We decided to focus on Fireflies (\emph{Lampyris noctiluca}) and their rhythmic and synchronizing behavior. We didn't wanted to make exact simulation, it was meant to relate to a feeling, or an atmosphere of the situation. For this purpose, I have developed little electronic insects - robots, built from LEDs and vibration motors. Vibration motors were hand-picked from broken cellphones our friends donated to us. 

The part of main technical concept became to insert these (in the end 10) little robots into various jars in a way, that they hit the glass with their bodies when turned on. This resulted in very cricket-like sound, since the vibration motors behave a little like wings of an insect, especially when turned on in short (one or two second) bursts. This triggered our inspiration and we have started to create various sequences with computer and Arduino board. Using a sequencing patch I specially made for this purpose, we have been able to work with these robots as with any other MIDI instrument.

Last technical detail is, that in the end, the whole system was running without a normal computer, but from a circuit I have designed specifically for this process. This made it possible to make the whole core of the installation very small, transportable and easy to operate.

\subsection{Concept and execution} After the more technical part was finished, we started to focus more on the sequencing and general aesthetics of the installation. This has ended up in decision leaving preprogrammed (or precomposed) sequences and thinking more in a level of a generative algorithm. 

First algorithm idea was to create set of metronomes controlling the rhythm of robots, similarly to Ligeti's \emph{Poème symphonique}. One metronome per robot, each metronome with slightly higher (increments were equal) tempo than previous, e. g.\ there could be one with tempo of 60, other with 64, next one with 68 and so on. We wanted to create something which would start in sync, than slowly disperse in variations and come back to a sync afterwards. After I did the calculations, it turned out to be impossible if we wanted to keep slow-sync start and reasonable time of the whole cycle (from sync to sync). According to my calculations it was coming to length from tens of hours to hundreds of days. No visitor would be able to possibly perceive it, so we decided to create artificial resets - resynchronizations. During resynchronization, new set of tempos is picked from the database and the whole sequence starts again.

The whole installation was set up, as mentioned, in my apartment. Core of the system was installed at the ceiling instead of a lamp. I have replaced the lamp with electricity socket, so it was possible to turn on the whole installation just by flicking of the regular light switch.

\subsection{Exhibition} After successful exhibition at my apartment (and slight problems with the police), we have been invited to present the installation at Krakers. Krakers is a yearly event happening in Cracow, dedicated to presenting little art collectives and mostly home galleries. We have setup the installation in another apartment and all together it was visited by more than 250 people. Many people have stayed with the installation for longer periods of time, simply enjoying the patterns emerging from the desynchronicity of this metronomic behavior.

\subsection{Conclusion} I really enjoyed this form of work, as well as collaboration with other artist. Especially an artist which comes from very different realities and contexts. I believe it resulted in fruitful combination of technical and aesthetic world and helped me with my own personal attitude towards creating public works of this kind.

\chapter{Conclusion}

\bibliographystyle{apacite} 
\bibliography{general}

\end{document} 
