Wireless network sonification
=============================

As a part of my experimentation with untraditional sources for musical or audial data I decided to extend on the layer of wireless networks. At beginning I had rather basic knowledge of "sniffing", in technical terms - harvesting all data streams on the network, not just those directed towards recipient. Sniffing is technique generally used by hackers, system administrators and network security experts. Its purpose is usually not malicious, yet when described as sniffing it carries negative connotations. ]

Sniffing is possible due to the characteristics of networks. Either with LAN (Local Area Network) or unencrypted WLAN (Wireless LAN), all data which are currently flowing trough the system are accessible to everyone, LAN adapter (network cards) than separate their part of the data using IP filtering. IP filtering in this case is a simple check whether current data packet is meant for the concrete user. Accessing not just data filtered by IP filter, but the whole traffic is made possible by turning off the IP filtering functionality of the card.

Classic example of a sniffing software is tcpdump. Tcpdump was developed at University of California in 1987 by Van Jacobson, Craig Leres and  Steven McCanne and its main use is traffic analysis. To quote, its manual entry reads "dump traffic on a network", but that is very reducing. Over the years since its first release it has became rather complicated and powerful tool. One of the features of tcpdump is fact, that it can work easily with both LAN or WLAN packets and therefore allows us to work on various sonification practices.

In the beginning of my artistic process I was considering few options, ways, and processes, but since I accidentally had to work on some audio software written in C, I decided to give try to writing my own sniffer extended by sonification. For the purposes of this program I used libpcap, which is a dedicated C library used for sniffing used by tcpdump (PCAP stands for Packet CAPture). The whole process took a little while, since I was not experienced C programmer and I had to learn the basics while writing the code. 

Finally I partly succeeded, by writing "Sonodump". Sonodump worked exactly as I wanted - it "sniffed" the network data and reflected current traffic. The conversion was done trough treating data harvested from the network as audio data - simple WAV file. User has only two options to select from - which interface should be used (wireless or wired) and what sample rate are we expecting. Use of the term sample rate is a bit tricky, because we don't really know the sample rate of the stream - it is not audio stream. We can just guess or purposefully select some to affect the sonification behaves. Lower sample rates turn out rather low-frequency based and higher contain much higher frequencies. This occurs simply because of the speed the network data are read, as it would be an obscure case of wavetable synthesis.

Sonodump already gave some interesting results, yet it wasn't very efficient. My programming skills weren't just on the right level to optimize the code properly. Therefore I need to look for other options. In autumn 2011 I was asked by organizer of AudioArt festival in Krakow, Marek ChoÅ‚oniewski to present my sonification work on his festival. Sonodump wasn't enough in this case - I needed something more powerful and interesting.

One of the questions was whether to treat the sonification process in more traditional way, where I wouldn't interact with the stream which I am sonifying. I felt inner conflict between keeping certain level of purity and working on the most successful and pleasant aesthetic experience. In the end the idea of live interaction with the stream of data won, with plan for achieving non-traditional way of control over the resulting sound. With image of this wild, partly unpredictable instrument I started to research other ways of sonification. 

Sonodump was not optimal and had few bugs, and I already saw some easier ways of achieving my goals using bunch of commands on Linux system. I have started to work with Linux / UNIX, because their system shell, like for example bash allows user to 'pipeline' commands between themselves. That means, that output of one process can be streamed in real time to another without user caring about any "middle-man" text file or thinking about memory. This comes very handy when you want to sonify something. On some distributions it is enough to write:

cat SONIFY_ME.txt > /dev/dsp 

Command "cat" read the file SONIFY_ME.txt - which is an regular text file and using the symbol ">", bash takes care of writing it to "/dev/dsp" - which is a virtual port for soundcard. Writing to this port opens a stream on the soundcard and plays given data. Very straight forward and clear to understand. This is still about work with static documents, but with tcpdump, it is enough to write:

tcpdump -i wlan0 -A > /dev/dsp

Tcpdump opens a packet capture at device "wlan0" (wireless module). Option "-A" means conversion of the characters to ASCII symbols (so we can always read them in terminal).
This already gives us some amount of sonification of the network with just single line of code. 

Next step was to thing about what other ways are there to experiment with. One of the options what would be to change the sample rate of the "/dev/dsp" (sound card) on-the-fly and thus change the resulting sound as with Sonodump. After some research on the topic it seemed rather complicated and bulky to do, so I had to think of some other method. That was when I discovered "aplay", part of ALSA sound system. ALSA is amongst OSS and Jack one of possible sound systems used for audio on Linux. The two most important functions of aplay for me was the possibility to read data from pipeline and to modify couple of the parameters of the reading. Great addition was that there could be unlimited amount of aplays playing at the same time, even from one source.